<template>
  <div>
    <div class="tw-bg-moreBGImage tw-h-96">
      <div
        class="row tw-justify-between tw-flex-wrap md:tw-flex-nowrap tw-text-white"
      >
        <div
          class="tw-text-3xl sm:tw-text-4xl tw-mt-5 sm:tw-mt-24 tw-ml-5 lg:tw-ml-36"
        >
          Groundbreaking studies on <br />
          the journey towards <br />
          Islamic instruction
        </div>
        <div
          class="sm:tw-w-1/2 tw-ml-5 sm:tw-ml-0 tw-mt-5 sm:tw-mt-24 tw-text-base sm:tw-text-lg tw-tracking-widest"
        >
          We believe our research will eventually lead to
          <br class="tw-hidden lg:tw-block" />
          artificial general intelligence, a system that can
          <br class="tw-hidden lg:tw-block" />
          solve human-level problems. Building safe
          <br class="tw-hidden lg:tw-block" />
          and beneficial AGI is our mission.
        </div>
      </div>
    </div>
    <div
      class="lg:tw-w-2/3 tw-mx-4 tw-border-l-4 lg:tw-mx-auto tw-mt-36 tw-text-lg"
    >
      <div class="row tw-justify-between">
        <div
          class="tw-w-4 tw-h-4 -tw-ml-2.5 tw-rounded-full tw-bg-primary-bg-color"
        ></div>
        <div class="tw-pl-4 lg:tw-pl-12 -tw-mt-5">
          <div class="tw-text-xl tw-font-medium tw-pb-5">Approaches</div>
          <div>
            Our model was trained using Reinforcement Learning from Human
            Feedback (RLHF), following the same techniques as InstructGPT, but
            with some variations in the data collection process. Initially, we
            trained a supervised model by enlisting human AI trainers to play
            both roles in conversations with an AI assistant. To help them craft
            responses, we provided the trainers with suggestions generated by
            the model. We then combined this new dialogue dataset with the
            InstructGPT dataset, which we adapted into a dialogue format.
          </div>
          <div class="tw-pt-6">
            To enable reinforcement learning, we needed to gather comparison
            data by ranking two or more model-generated responses based on
            quality. To obtain this data, we utilized conversations between the
            AI trainers and the chatbot, randomly selecting a model-generated
            message and offering several alternative completions for the
            trainers to rank. Using these reward models, we fine-tuned the model
            via Proximal Policy Optimization, repeating this process multiple
            times.
          </div>
        </div>
      </div>
      <div class="row tw-justify-between tw-mt-24">
        <div
          class="tw-w-4 tw-h-4 -tw-ml-2.5 tw-rounded-full tw-bg-primary-bg-color"
        ></div>
        <div class="tw-pl-4 lg:tw-pl-12 -tw-mt-5">
          <div class="tw-text-xl tw-font-medium tw-pb-5">Constraints</div>
          <div>
            Sometimes CHATISLAM, our advanced AI chatbot for Islam, generates
            responses that sound plausible but are either incorrect or
            nonsensical. Fixing this issue has proven to be difficult due to
            several factors. Firstly, during reinforcement learning training,
            there is currently no source of truth to guide the model towards the
            correct answer. Secondly, training the model to be more cautious can
            cause it to decline questions that it could answer correctly.
            Lastly, supervised training can be misleading, as the ideal answer
            depends on what the model knows, rather than what the human
            demonstrator knows.
          </div>
          <div class="tw-pt-6">
            CHATISLAM, like other AI models, is also sensitive to input phrasing
            and repetition of prompts. For example, when presented with a
            particular phrasing of a question, the model may claim not to know
            the answer, but with a slight rephrasing, can answer correctly.
            Biases in the training data can cause the model to be excessively
            verbose and overuse certain phrases, such as restating that it's an
            advanced AI chatbot trained by OpenAI. This issue arises because
            trainers prefer longer answers that appear more comprehensive,
            leading to well-known over-optimization issues.
          </div>
          <div class="tw-pt-6">
            Ideally, CHATISLAM would ask clarifying questions when presented
            with an ambiguous query. However, our current models usually guess
            what the user intended. While we have implemented measures to make
            the model refuse inappropriate requests, it can sometimes respond to
            harmful instructions or exhibit biased behavior. We are using the
            Moderation API to warn or block certain types of unsafe content, but
            we expect it to have some false negatives and positives for now. We
            welcome user feedback to aid us in our ongoing efforts to improve
            the system.
          </div>
        </div>
      </div>
      <div class="row tw-justify-between tw-mt-24">
        <div
          class="tw-w-4 tw-h-4 -tw-ml-2.5 tw-rounded-full tw-bg-primary-bg-color"
        ></div>
        <div class="tw-pl-4 lg:tw-pl-12 -tw-mt-5">
          <div class="tw-text-xl tw-font-medium tw-pb-5">
            Continuous AI deployment
          </div>
          <div>
            Certainly! ChatIslam (the advanced Islamic AI chatbot) represents a
            significant step forward in the development of AI systems that are
            not only useful, but also safe for users. This is a critical
            consideration, as the use of AI has the potential to transform many
            aspects of our lives, from healthcare to education and beyond.
            However, as with any new technology, there are risks and challenges
            that need to be addressed. In the case of AI chatbots like
            ChatIslam, these include the potential for harmful or untruthful
            outputs, as well as issues with bias and sensitivity to input
            phrasing.
          </div>
          <div class="tw-pt-6">
            To address these challenges, ChatIslam has been developed using the
            latest techniques in AI safety, including reinforcement learning
            from human feedback (RLHF). This approach enables the model to learn
            from real-world interactions with users, allowing it to improve its
            responses over time. In addition, the ChatIslam team has implemented
            a range of safety measures, including the use of a Moderation API to
            detect and block unsafe content. The team is also actively seeking
            user feedback to help identify and address any issues that arise.
          </div>
          <div class="tw-pt-6">
            Overall, ChatIslam represents an exciting advance in the development
            of AI systems that are not only effective, but also safe and
            reliable for users. As this technology continues to evolve, it has
            the potential to transform many aspects of our lives for the better.
          </div>
        </div>
        <div
          class="tw-w-4 tw-h-4 -tw-ml-2.5 tw-rounded-full tw-mt-7 tw-bg-primary-bg-color"
        ></div>
      </div>
    </div>
    <div class="tw-mt-24">
      <div class="tw-text-center tw-text-2xl">Related</div>
      <div class="row tw-justify-center sm:tw-flex-nowrap tw-mt-5">
        <div class="tw-mx-4 sm:tw-mx-1 lg:tw-mx-4 tw-mt-28 md:tw-mt-0">
          <q-img
            src="~assets/img/pharm.png"
            class="tw-w-80 sm:tw-w-64 lg:tw-w-80 tw-rounded-3xl img-gradient"
          />
          <div
            class="-tw-mt-28 tw-text-white tw-relative tw-text-center tw-font-medium tw-text-2xl"
          >
            Pharmacy
          </div>
        </div>
        <div class="tw-mx-4 sm:tw-mx-1 lg:tw-mx-4 tw-mt-28 md:tw-mt-0">
          <q-img
            src="~assets/img/science.png"
            class="tw-w-80 sm:tw-w-64 lg:tw-w-80 tw-rounded-3xl img-gradient"
          />
          <div
            class="-tw-mt-28 tw-text-white tw-relative tw-text-center tw-font-medium tw-text-2xl"
          >
            Science
          </div>
        </div>
        <div class="tw-mx-4 sm:tw-mx-1 lg:tw-mx-4 tw-mt-28 md:tw-mt-0">
          <q-img
            src="~assets/img/finance.png"
            class="tw-w-80 sm:tw-w-64 lg:tw-w-80 tw-rounded-3xl img-gradient"
          />
          <div
            class="-tw-mt-28 tw-text-white tw-relative tw-text-center tw-font-medium tw-text-2xl"
          >
            Finance
          </div>
        </div>
      </div>
    </div>
  </div>
  <AppFooter />
</template>

<script>
import { defineComponent } from "vue";
import AppFooter from "src/components/AppFooter.vue";

export default defineComponent({
  components: { AppFooter },
  setup() {},
});
</script>

<style>
.img-gradient {
  position: relative;
  display: inline-block;
}

/*
#002f4b,#dc4225
Convert HEX to RGBA - http://hex2rgba.devoth.com/
*/
.img-gradient:after {
  content: "";
  position: absolute;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  display: inline-block;
  background: -moz-linear-gradient(
    top,
    rgba(0, 47, 75, 0.5) 0%,
    #0c1f50 100%
  ); /* FF3.6+ */
  background: -webkit-gradient(
    linear,
    left top,
    left bottom,
    color-stop(0%, #0c1f50),
    color-stop(100%, rgba(0, 47, 75, 0.5))
  ); /* Chrome,Safari4+ */
  background: -webkit-linear-gradient(
    top,
    rgba(0, 47, 75, 0.5) 0%,
    #0c1f50 100%
  ); /* Chrome10+,Safari5.1+ */
  background: -o-linear-gradient(
    top,
    rgba(0, 47, 75, 0.5) 0%,
    #0c1f50 100%
  ); /* Opera 11.10+ */
  background: -ms-linear-gradient(
    top,
    rgba(0, 47, 75, 0.5) 0%,
    #0c1f50 100%
  ); /* IE10+ */
  background: linear-gradient(
    to bottom,
    rgba(0, 47, 75, 0.5) 0%,
    #0c1f50 100%
  ); /* W3C */
  filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#002f4b', endColorstr='#00000000',GradientType=0 ); /* IE6-9 */
}
.img-gradient img {
  display: block;
}
</style>
